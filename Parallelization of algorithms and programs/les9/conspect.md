## OpenMP

Мы сегодня начинаем с вами заниматься второй технологией параллельного программирования - OpenMP

Надо сказать что с MPI мы не до конца закончили, с ним будем еще сталкиваться на самой последней нашей практике при объединении. 

Здесь - набор нитей исполнения, которое работает в общей памяти. Определенный недостаток - работая в общей памяти мы будем работать в рамках одного узла на кластере. 4 ядра - максимум

Принципы технологии OpenMP:
1) Распараллеливание будет вставляться через pragm'ы
2) В программе выделяются последовательные и параллельные области - причем чередуются 
Программа представляет себя череду последовательных и параллельных участоков 
3) Программа всегда начинается с последовательной частью - master-нить (когда процесс родился и встал в состояние готовности)
4) При входе в параллельную область будут порождаться еще некоторые нити между которыми распределяется выполнение кода параллельной области
5) При выходе из параллельной области все нити кроме главной нити (master - нити) завершаются
Мы будем писать pragm'ы с соответствующими нитями исполнения 

### Прагмы и директивы 
Общий вид:
```cpp
#pragma omp pragma-name [опция[...], опция[...]]
```
Область действия - оператор или блок операторов в фигурных скобках непосредственно следующий за прагмой

Категории прагм:
1) Определение параллельной области
2) распределение работы в параллельной области
3) Синхронизация работы нитей исполнения

Для использования процедур в программу необходимо включить include-файл
```cpp
#include <omp.h>
```

Имена вcех процедур в OpenMP начинаются с префикса omp..

Процедуры используются:
1) Для получения информации о режимах работы программы
2) Для установления таких режимов работы 
3) 

### Определение параллельной области
```cpp
#pragma omp parallel [опция[...], опция[...]]
```
Пример:

```c
#include <stdio.h>

int main() { //последовательная часть
    printf("Sequential part 1\n");
#pragma omp parallel
    {
        printf("Parallel part\n");    
    }
    printf("Sequential part 2\n");
    return 0;
}
```

Как запускать для главного узла и счетные узлы будем использовать?

### Компиляция
```bash
gcc source.c -o exefile -fopenmp
```

```bash
g++ source.cpp -o exefile -fopenmp
```

### Двигаемся дальше
Теперь будем в дальнейшем запускаться на счетных узлах - на головном узле все пишут, поэтому незачем его затруднять своими openmp

#### Измерение количества нитей
Вспомогательная процедура
```c
void omp_set_num_threads(int num)
```
или опция parallel:
```c
num_threads(num)
```
Например:
```c
#pragma omp parallel num_threads(5) // 5 нитей исполнения включая главную
```
Отличия? Опция прагма влияет на ту параллельную область, перед которой мы ставим количество нитей (учитывая матсер-нить)

Если я вызвал вспомогательную процедуру - то устанавливаю количество threads будет действовать во всех параллельных областях. Процедура 1 раз делается, прагма рабоатет только на 1 параллельную область. 

Пример:
```c
#include <stdio.h>
#include <omp.h>

int main() {
    printf("Sequential part 1\n");
    omp_set_num_threads(3);
#pragma omp parallel
    {
        printf("Parallel part\n");    
    }
    printf("Sequential part 2\n");
    return 0;
}
```

Через скрипт так же запускаемся
```bash 
qsub omp.sh
```

### Виды пременных в нитях
Параллельные части все переменные делятся на 2 вида
1) shared - общие для всех нитей 
2) private - у каждой нити свое

По умолчанию все перменные (без слова static) private; static - переменная не лежит в стэке, лежит в статической памяти, не может быть приватной, будет переменной shared. По умолчанию все переменные, описанные вне параллельного блока - shared, также память выделяемая динамически через malloc. Сама память - общая! А указатель на начало можно сделать приватным

Важно отметить, что переменные описанные без слова static внутри параллельного блока не сделать приватными. Внешние переменные можно приватизировать с использованием опций директивы parallel

Лучше нагляднее все переменные обзывать по своему
```c
shared(имя[, имя[, ...]])
private(имя[, имя[, ...]])
```
Пример:
```c
int a=2, b=1, c[10], d[2]={1,1};
#pragma omp parallel shared(b,c) private(a,d)
```
Переменные, приватизированные с помощью private имею неопределенное начальное состояние
```c
#include <stdio.h>

int x0 = 2;
int main() {
    int x1 = 2;
#pragma omp parallel shared(x0,x1)
    {
        int x2 = 1; 
        static int x3=1;
        x0++; x1++; x2++; x3++;
        printf("Par x0=%d x1=%d x2=%d x3=%d\n", x0, x1, x2, x3);
    }
    return 0;
}
```
x0, x1, - от 3 до 6 будет, x3 - от 2 до 5 - потому что thread'ы могут отбирать у нас. А вот x2 будет стабильно 2 - с ним все харашо

Поменяем немного текст
```c
#include <stdio.h>

int x0 = 2;
int main() {
    int x1 = 2;
#pragma omp parallel shared(x0), private(x1)
    {
        int x2 = 1; 
        static int x3=1;
        x0++; x1++;/*непонятно что будет лежать тк сделали приватным*/ x2++; x3++;
        printf("Par x0=%d x1=%d x2=%d x3=%d\n", x0, x1, x2, x3);
    }
    printf("Seq x0=%d x1=%d\n", x0,x1);
    return 0;
}
//когда создаются копии - внешнюю переменную не трогаем, и в x1 будет лежать это же число что и было
```

Для приватизации переменных в параллельном блокае с сохранением последнгео значения, присвоенного перед блоком, используется опция firstprivate

### Информационные процедуры
Определение количества исполнителей (количество ядер)
```c
int omp_get_num_procs(void)
```
Определение количества работающих нитей
```c
int omp_get_num_thread(void)
```
Определение номера текущей нити
```c
int omp_get_thread_num(void)
```
#### Директива threadprivate
Нужна для того, чтобы позволить организовать приватные переменные, которые будут сохранять свои значения для разных параллельных областей 

на эту директиву есть определенные ограничения - указывается вне параллельных областей, применяется только к статическим переменным, применяется до первого использования перемнных из списка 

Отличается от обычных - при объявления threadprivate копия не создается, а используется то что и было. Когда я выйду тогда и будет значение. В x0 не будет печататься 5, а 1

### Задача Hello OMP
2 последовательные и 1 параллельные части

1 последовательная часть - еоличество ядер на узле
в параллельной части запускаем 6 нитей каждая из ни приветствует OMP и сообщает свой номер
во 2 последовательной части напечатайте номер работающей нити и количество нитей