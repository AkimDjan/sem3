## Семинар 5

### Замечания
Сначала некоторые замечания

1) Надо присылать исходник 
2) Надо присылать **только** исходник
3) Внимательно слушаем формулировки задач и делать то что он скажет
4) Придерживаемся определенной логики
5) Сегодня модернизируем одну из прошлых задач  - ВНИМАТЕЛЬНО СЛУШАЕМ ФОРМУЛИРОВКИ

### Теория по групповым операциям - MPI_Bcast и MPI_Reduce
Сегодня начинаем групповыми операциями

Прошлый раз сделали так - в памяти одного процесса есть данные, мы передаем каждому процессу

Есть еще способ - N исполнителей, им всем нужны данные. распишем по шагам
1) 1 шаг - 1ый процесс обменивается информацией со вторым, и второй кладет к себе
2) след шаг - 1 с 3ьим а второй с 4, делают одновременно, за весь этот шаг информация лежит на 4 процессах
3) на третьем шаге 1 - 5, 2-6, 3-7, 4-8

Трудоемкий процсс для отладки, вместо того, чтобы заставлять программистов руками писать через point-to-point - введена MPI_Bcast - сокращенна от Broadcast

Проверка обязательна!!!
```cpp
int MPI_Bcast (void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) 
```
1) comm - коммуникатор группы процессов для этой операции;
1 процесс рассылает, все остальные - принимающие (все этой же функции) и для приема и для передачи

2) root - рассыльщик - ранг
3) buffer - адрес в памяти, где лежит информация для рассылающего, для принимающих - куда поместить
4) count - количество
5) Datatype - тип данных

Следующая групповая операция - которая нам понадобится - MPI_Reduce

Пример: пусть у ас есть N процессов и N значений. Хотим посчитать сумму значений - положить в ячейку

Можно - последовательно идти по процессам и суммировать каждое значение в сигму (sum+=a_i) (teta(N))

Можно и нужно - (аля бинарный поиск) берем и рассчитываем суммы макисмальной степени двойки, последовательно считаем так

Примеры редукционных операций:+,*,&,|,&&,||,max,min

Не забываем проверять значение!

```cpp
int MPI_Reduce (void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm) 
```

1) op - код операции, которую хочу выполнить (MPI_SUM, MPI_PROD, MPI_LAND ... )
2) sendbuf – адрес памяти, где у процесса лежат исходные данные (у каждого процесса может быть свой)
3) recvbuf – адрес памяти, куда будет занесен результат, - реально используется только на процессе с ранком root
4) root – ранк процесса в группе, описываемой коммуникатором comm, на который нужно поместить результат
5) comm – коммуникатор группы процессов для групповой операции
6) count – количество данных (элементов типа datatype) для операции
7) datatype – тип данных, над которыми выполняется операция

### Смысл Задачи 1
В программе с прошлого занятия прочитали N из файла процессом ранга 0, рассылали циклом... Заменяем Broadcast

Там где применяли и посылали в конце - делаем MPI_Reduce

Модифицируем программу с использованием MPI_Bcast и MPI_Reduce

### Далее - MPI_Gather 
Новая групповая функция - MPI_Gather - предназначена для собирания информации в конце воедино

Пусть есть массив данных, который надо обсчитать в нашей параллельной программе

Количество исполнителей пусть 3

Высянилось хорошо, что когда вбиваю исходный массив на зоны ответственности - на три поделился нацело => sizы. Пусть 0, 1, 2 считают свои sizeы. Пусть есть процесс root - ему мы кладем 0-1-2 значения посчитанных операций. Можно point-to-point, но не надо

обязательно проверка

```cpp
int MPI_Gather (void *sendbuf, int sendcount, 
MPI_Datatype sendtype, void *recvbuf, int recvcount, 
MPI_Datatype recvtype, int root, MPI_Comm comm) 
```
1) sendbuf – адрес памяти, где у процесса лежат собираемые данные  (у каждого процесса может быть свой) 
2) sendcount – количество собираемых данных с процесса (должно быть одинаково для всех процессов)
3) sendtype – тип собираемых данных (должен быть одинаков для всех процессов)
4) recvbuf – адрес памяти, начиная с которого будут упорядоченно складываться собираемые данные (использует только root), НЕ может совпадать с sendbuf.
5) recvcount  – количество собираемых данных с процесса (использует только root, должно совпадать с sendcount)
6) recvtype – тип собираемых данных (использует только root, должен совпадать с sendtype)
7) root – ранг собирающего процесса 
8) comm – коммуникатор группы процессов

Еще замечание - пусть у меня есть следующая ситуация 
(фото что от 2 и 0 передается 1 - он root)
Для такой передачи данных на процессе с рангом root (и только на нем!) вместо sendbuf указывается MPI_IN_PLACE


